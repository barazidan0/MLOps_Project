# -*- coding: utf-8 -*-
"""eda-of-netflix-dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-3c43kbXg8ROqi1OKfVM4DV2sUz04j3h

# Importing necessary libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import mlflow
import mlflow.sklearn
# %matplotlib inline
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, silhouette_samples, calinski_harabasz_score, davies_bouldin_score

! pip install mlflow

"""# Loading csv"""

url = 'https://raw.githubusercontent.com/barazidan0/MLOps_Project/refs/heads/main/titles.csv'

df= pd.read_csv(url)
df.head()

df.describe()

"""# Data cleaning"""

df["seasons"]=df["seasons"].fillna(0)
df["imdb_score"]=df["imdb_score"].fillna(df["imdb_score"].mean())
df["imdb_votes"]=df["imdb_votes"].fillna(df["imdb_votes"].median())
df["tmdb_popularity"]=df["tmdb_popularity"].fillna(df["tmdb_popularity"].median())
df["tmdb_score"]=df["tmdb_score"].fillna(df["tmdb_score"].mean())
df2=df.drop(["imdb_id","description","age_certification"], axis=1)
df2.head()

df2=df2.dropna()

df2.isna().sum()

#df.to_csv('netflix_cleaned.csv', index=False)

df2.shape

vc=df2["type"].value_counts()
vc

sns.countplot(data= df2, x="type")
plt.figure(figsize= (6,6), label=vc)
plt.show()

df2.dtypes

df2.info()

df2.drop_duplicates()

df2["genres"]=df2["genres"].to_numpy().astype(str)
df2["production_countries"]=df2["production_countries"].to_numpy().astype(str)
df2

df2.dtypes

"""# Action movies"""

df2[df2["genres"].str.contains('action')]

"""# EXPLORATORY DATA ANALYSIS

# Univariate analysis
"""

sns.boxplot(df2[['imdb_score','tmdb_score']])

"""Terdapat banyak outlier pada imdb_score dan tmdb_score di seluruh dataset."""

df2["production_countries"].value_counts()[:10].plot(kind='barh')

"""Amerika Serikat, India, dan Jepang merupakan tiga negara produksi Netflix teratas.

# MOVIE & SHOW distribution in India
"""

df2[df2["production_countries"].str.contains('IN')].type.value_counts().plot(kind='bar')

"""split dataframe kedalam MOVIE & SHOW types.

# dfm is for MOVIES and dfs is for SHOWS
"""

dfm=df2[df2["type"]=="MOVIE"]
dfs=df2[df2["type"]=="SHOW"]

"""# Frequency plot of number of seasons"""

dfs["seasons"].value_counts().plot(kind='bar')

"""Sebagian besar show hanya memiliki 1 musim, sepertiganya memiliki 2 musim, dan setengah dari jumlah tersebut memiliki 3 musim."""

plt.figure(figsize=(12,12))
sns.countplot(x='release_year', data=df2)
plt.show()

"""Terdapat pertumbuhan signifikan dalam jumlah konten yang dibuat atau dirilis dalam 5 tahun terakhir.

# BIVARIATE ANALYSIS

# Scatterplot
"""

sns.scatterplot(x="imdb_score", y="tmdb_score", hue="type", data=df2)

cm = df2.drop(['id', 'title', 'genres', 'production_countries', 'type'], axis=1)
sns.heatmap(cm.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.show()

"""Secara umum, Show cenderung memiliki imdb score dan tmdb score yang lebih tinggi dibandingkan Movie."""

plt.figure(figsize=(12,12))
sns.pairplot(data=df2, hue="type")
plt.show()

"""Pairplot ini memberikan beberapa insight utama terkait Show dan Movie:

1.  Terdapat peningkatan signifikan baik pada Show maupun Movie dalam 5 tahun terakhir.
2. tmdb_popularity untuk Movie secara signifikan lebih tinggi dibandingkan Show.
3. imdb_score dan tmdb_score untuk Movie relatif lebih rendah.
4. Durasi tayang (runtime) untuk Movie umumnya lebih panjang dibandingkan sebagian besar Show.

KESIMPULAN

Amerika Serikat, India, dan Jepang merupakan tiga negara produksi Netflix terbesar.
Terdapat peningkatan signifikan baik pada Show maupun Movie dalam 5 tahun terakhir.
tmdb_popularity untuk Movie secara signifikan lebih tinggi dibandingkan Show.
imdb_score dan tmdb_score untuk Movie relatif lebih rendah dibandingkan Show.
"""

pre_df = df2[['title', 'imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score']]
pre_df.head(5)

pre_df.describe()

pre_df['imdb_votes'] = np.log(pre_df['imdb_votes'] + 1)
pre_df['tmdb_popularity'] = np.log(pre_df['tmdb_popularity'] + 1)
pre_df.describe()

# Plot histograms to see the distribution
fig, axs = plt.subplots(2, 2, figsize=(14, 10))

# Histograms for transformed data
# Use pre_df and the correct column names after transformation
sns.histplot(pre_df['imdb_votes'], bins=30, kde=True, ax=axs[0, 0], color='skyblue')
axs[0, 0].set_title('Log Transformed IMDB Votes')

sns.histplot(pre_df['tmdb_popularity'], bins=30, kde=True, ax=axs[0, 1], color='lightgreen')
axs[0, 1].set_title('Log Transformed TMDB Popularity')

# These plots are for the original (or cleaned) scores, which are still in pre_df
sns.histplot(pre_df['imdb_score'], bins=30, kde=True, ax=axs[1, 0], color='salmon')
axs[1, 0].set_title('IMDB Score')

sns.histplot(pre_df['tmdb_score'], bins=30, kde=True, ax=axs[1, 1], color='lightcoral')
axs[1, 1].set_title('TMDB Score')

plt.tight_layout()
plt.show()

# Persiapan data
pre_df = df2[['title', 'imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score']].copy()
pre_df['imdb_votes'] = np.log(pre_df['imdb_votes'] + 1)  # Transformasi log untuk mengurangi skewness
pre_df['tmdb_popularity'] = np.log(pre_df['tmdb_popularity'] + 1)  # Transformasi log

# Melakukan standarisasi data
X_scaled = StandardScaler().fit_transform(pre_df[['imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score']])

# Inisialisasi dan training model KMeans
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)  # Tambahkan n_init untuk stabilitas
pre_df['cluster'] = kmeans.fit_predict(X_scaled)  # Menambahkan hasil cluster ke dataframe

# Inisialisasi eksperimen MLflow
mlflow.set_experiment("KMeans Netflix")

# Mengakhiri run aktif sebelumnya (jika ada)
mlflow.end_run()

# Memulai pencatatan run baru
with mlflow.start_run():
    mlflow.log_param("model", "KMeans")  # Mencatat jenis model
    n_clusters = 3  # Jumlah cluster yang digunakan
    mlflow.log_param("clusters", n_clusters)  # Mencatat jumlah cluster

    from sklearn.metrics import silhouette_score, silhouette_samples  # Impor fungsi evaluasi

    # Menghitung dan mencatat skor silhouette
    silhouette_avg = silhouette_score(X_scaled, pre_df['cluster'])
    ch_score = calinski_harabasz_score(X_scaled, pre_df['cluster'])
    db_score = davies_bouldin_score(X_scaled, pre_df['cluster'])

    mlflow.log_metric("silhouette", silhouette_avg)
    mlflow.log_metric("calinski_harabasz_score", ch_score)
    mlflow.log_metric("davies_bouldin_score", db_score)

    # Simpan model ke MLflow
    mlflow.sklearn.log_model(kmeans, "model")

    # Visualisasi hasil clustering
    plt.figure(figsize=(8, 5))
    sns.scatterplot(x=X_scaled[:, 0], y=X_scaled[:, -1], hue=pre_df['cluster'], palette='viridis')
    plt.title("Clustering (imdb_score vs tmdb_score)")
    plt.savefig("cluster.png")  # Simpan gambar
    mlflow.log_artifact("cluster.png")  # Upload ke MLflow
    plt.show()

    # Visualisasi plot silhouette
    silhouette_vals = silhouette_samples(X_scaled, pre_df['cluster'])  # Hitung nilai silhouette
    plt.figure(figsize=(10, 6))

    y_lower = 10
    unique_clusters = sorted(pre_df['cluster'].unique())  # Ambil label cluster unik
    for i in unique_clusters:
        ith_vals = silhouette_vals[pre_df['cluster'] == i]
        ith_vals.sort()
        size_cluster_i = ith_vals.shape[0]
        y_upper = y_lower + size_cluster_i
        color = plt.cm.nipy_spectral(float(i) / n_clusters)
        plt.fill_betweenx(np.arange(y_lower, y_upper),
                          0, ith_vals,
                          facecolor=color, edgecolor=color, alpha=0.7)

        # Beri label angka cluster di tengah plotnya
        plt.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))

        # Ubah posisi bawah untuk cluster berikutnya
        y_lower = y_upper + 10

    plt.axvline(x=silhouette_avg, color="red", linestyle="--")  # Garis rata-rata silhouette
    plt.xlabel("Nilai Koefisien Silhouette")
    plt.ylabel("Label Cluster")
    plt.title("Plot Silhouette untuk Setiap Cluster")
    plt.savefig("silhouette_plot.png")  # Simpan plot
    mlflow.log_artifact("silhouette_plot.png")  # Upload ke MLflow
    print('\n')
    plt.show()

    # Tampilkan jumlah data pada setiap cluster
    print("\nJumlah data per cluster:")
    print(pre_df['cluster'].value_counts())